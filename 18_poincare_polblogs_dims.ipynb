{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"GEOMSTATS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from geomstats.geometry.hyperbolic import Hyperbolic\n",
    "from geomstats.datasets.prepare_graph_data import HyperbolicEmbedding, Graph\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from src.hyperdt.tree import DecisionTreeClassifier, HyperbolicDecisionTreeClassifier\n",
    "from src.hyperdt.forest import HyperbolicRandomForestClassifier\n",
    "from src.hyperdt.conversions import convert\n",
    "\n",
    "from hyperbolics.utils.distortions import map_score, distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from 17_graphs_2.ipynb\n",
    "\n",
    "\n",
    "def load_graph(graph_dir, graph_type=\"directed\", edge_type=\"unweighted\", add_isolates=False, top_cc=False):\n",
    "    # Specify paths\n",
    "    adjacency_path = f\"{graph_dir}/adjacency.tsv\"\n",
    "    dense_adjacency_path = f\"{graph_dir.replace('/raw/', '/interim/')}/adjacency_dense.tsv\"\n",
    "    labels_path = f\"{graph_dir}/labels.tsv\"\n",
    "    label_names_path = f\"{graph_dir}/names_labels.tsv\"\n",
    "    names_path = f\"{graph_dir}/names.tsv\"\n",
    "\n",
    "    # Adjacency matrix: (out_node, in_node)\n",
    "    adjacency = pd.read_table(adjacency_path, header=None, usecols=[0, 1])\n",
    "\n",
    "    # Labels: (label, )\n",
    "    labels = pd.read_table(labels_path, header=None, usecols=[0])[0]\n",
    "\n",
    "    # Label name: (label_name, )\n",
    "    if os.path.exists(label_names_path):\n",
    "        label_names = pd.read_table(label_names_path, header=None, usecols=[0])[0]\n",
    "    else:\n",
    "        label_names = pd.Series(labels[0].unique()).reset_index()\n",
    "\n",
    "    # Node name: (node_name, )\n",
    "    if os.path.exists(names_path):\n",
    "        names = pd.read_table(names_path, header=None, usecols=[0])[0]\n",
    "    else:\n",
    "        names = pd.Series(np.arange(len(labels))).reset_index()\n",
    "\n",
    "    # Networkx object\n",
    "    base_graph = nx.DiGraph if graph_type == \"directed\" else nx.Graph\n",
    "    networkx_graph = nx.from_pandas_edgelist(adjacency, source=0, target=1, create_using=base_graph)\n",
    "    if add_isolates:\n",
    "        networkx_graph.add_nodes_from(names.index)\n",
    "\n",
    "    # Add names and labels to nodes\n",
    "    nx.set_node_attributes(networkx_graph, dict(zip(names.index, labels)), \"label\")\n",
    "    networkx_graph = nx.relabel_nodes(networkx_graph, dict(zip(names.index, names)))\n",
    "\n",
    "    # Get connected components\n",
    "    if top_cc:\n",
    "        networkx_graph = networkx_graph.subgraph(max(nx.connected_components(networkx_graph), key=len))\n",
    "\n",
    "    # Pairwise distances\n",
    "    distances = nx.floyd_warshall_numpy(networkx_graph)\n",
    "\n",
    "    # Geomstats object\n",
    "    dense_adjacency = nx.to_numpy_array(networkx_graph)\n",
    "    np.savetxt(dense_adjacency_path, dense_adjacency, fmt=\"%d\", delimiter=\"\\t\")\n",
    "    geomstats_graph = Graph(graph_matrix_path=dense_adjacency_path, labels_path=labels_path)\n",
    "\n",
    "    return {\n",
    "        \"labels\": list(networkx_graph.nodes(data=\"label\")),\n",
    "        \"label_names\": list(label_names),\n",
    "        \"names\": list(networkx_graph.nodes()),\n",
    "        \"networkx_graph\": networkx_graph,\n",
    "        \"geomstats_graph\": geomstats_graph,\n",
    "        \"distances\": distances,\n",
    "    }\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "polblogs = load_graph(\"data/raw/polblogs\", graph_type=\"undirected\", top_cc=True)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "def assess_embedding(embedding, true_dists=polblogs[\"distances\"], dim=2, coords=\"ball\"):\n",
    "    # Clip to max distance in embeddings\n",
    "    manifold = Hyperbolic(dim, default_coords_type=coords)\n",
    "    pairwise_dists = squareform(pdist(embedding, metric=manifold.metric.dist))\n",
    "    graph_dists = np.clip(true_dists, a_min=None, a_max=np.max(pairwise_dists))\n",
    "\n",
    "    # Assess distortion:\n",
    "    distortion_val = distortion(graph_dists, pairwise_dists, n=len(graph_dists), jobs=-1)\n",
    "    map_val = map_score(graph_dists, pairwise_dists, n=len(graph_dists), jobs=-1)\n",
    "    return distortion_val, map_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labels for convenience\n",
    "\n",
    "labels = polblogs[\"labels\"]\n",
    "labels = pd.DataFrame(labels)\n",
    "labels = labels.set_index(0)\n",
    "labels.to_csv(\"data/processed/polblogs_labels.csv\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Number of edges: 1222\n",
      "INFO: Mean vertices by edges: 27.357610474631752\n",
      "INFO: iteration 0 loss_value 2.688718\n",
      "INFO: iteration 1 loss_value 2.637627\n",
      "INFO: iteration 2 loss_value 2.614299\n",
      "INFO: iteration 3 loss_value 2.585342\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/hdt/18_poincare_polblogs_dims.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/18_poincare_polblogs_dims.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/18_poincare_polblogs_dims.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     embed \u001b[39m=\u001b[39m HyperbolicEmbedding(dim\u001b[39m=\u001b[39membed_dim, n_negative\u001b[39m=\u001b[39mn_neg, n_context\u001b[39m=\u001b[39mn_con, lr\u001b[39m=\u001b[39mlr, max_epochs\u001b[39m=\u001b[39mepochs)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/18_poincare_polblogs_dims.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     polblogs_gs_embed \u001b[39m=\u001b[39m embed\u001b[39m.\u001b[39membed(polblogs[\u001b[39m\"\u001b[39m\u001b[39mgeomstats_graph\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/18_poincare_polblogs_dims.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEmbedding shape: \u001b[39m\u001b[39m{\u001b[39;00mpolblogs_gs_embed\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/18_poincare_polblogs_dims.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/geomstats/datasets/prepare_graph_data.py:305\u001b[0m, in \u001b[0;36mHyperbolicEmbedding.embed\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m context_embedding \u001b[39m=\u001b[39m embeddings[one_context_i]\n\u001b[1;32m    300\u001b[0m negative_embedding \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39mget_slice(\n\u001b[1;32m    301\u001b[0m     embeddings,\n\u001b[1;32m    302\u001b[0m     gs\u001b[39m.\u001b[39msqueeze(gs\u001b[39m.\u001b[39mcast(one_negative_i, dtype\u001b[39m=\u001b[39mgs\u001b[39m.\u001b[39mint64)),\n\u001b[1;32m    303\u001b[0m )\n\u001b[0;32m--> 305\u001b[0m l, g_ex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(\n\u001b[1;32m    306\u001b[0m     example_embedding, context_embedding, negative_embedding\n\u001b[1;32m    307\u001b[0m )\n\u001b[1;32m    308\u001b[0m total_loss\u001b[39m.\u001b[39mappend(l)\n\u001b[1;32m    310\u001b[0m example_to_update \u001b[39m=\u001b[39m embeddings[one_path]\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/geomstats/datasets/prepare_graph_data.py:216\u001b[0m, in \u001b[0;36mHyperbolicEmbedding.loss\u001b[0;34m(self, example_embedding, context_embedding, negative_embedding)\u001b[0m\n\u001b[1;32m    212\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m(positive_loss \u001b[39m+\u001b[39m gs\u001b[39m.\u001b[39msum(negative_loss))\n\u001b[1;32m    214\u001b[0m positive_log_sigmoid_grad \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad_log_sigmoid(\u001b[39m-\u001b[39mpositive_distance)\n\u001b[0;32m--> 216\u001b[0m positive_distance_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad_squared_distance(\n\u001b[1;32m    217\u001b[0m     example_embedding, context_embedding\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m positive_grad \u001b[39m=\u001b[39m (\n\u001b[1;32m    221\u001b[0m     gs\u001b[39m.\u001b[39mrepeat(positive_log_sigmoid_grad, dim, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m positive_distance_grad\n\u001b[1;32m    222\u001b[0m )\n\u001b[1;32m    224\u001b[0m negative_distance_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad_squared_distance(\n\u001b[1;32m    225\u001b[0m     reshaped_example_embedding, negative_embedding\n\u001b[1;32m    226\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/geomstats/datasets/prepare_graph_data.py:169\u001b[0m, in \u001b[0;36mHyperbolicEmbedding.grad_squared_distance\u001b[0;34m(self, point_a, point_b)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Gradient of squared hyperbolic distance.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[39mGradient of the squared distance based on the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m    Geodesic squared distance between the two points.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m hyperbolic_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanifold\u001b[39m.\u001b[39mmetric\n\u001b[0;32m--> 169\u001b[0m log_map \u001b[39m=\u001b[39m hyperbolic_metric\u001b[39m.\u001b[39mlog(point_b, point_a)\n\u001b[1;32m    171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m log_map\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/geomstats/geometry/poincare_ball.py:152\u001b[0m, in \u001b[0;36mPoincareBallMetric.log\u001b[0;34m(self, point, base_point, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog\u001b[39m(\u001b[39mself\u001b[39m, point, base_point, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    137\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Riemannian logarithm of a point wrt a base point.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m        of point at the base point.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     mobius_addition \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmobius_add(\u001b[39m-\u001b[39mbase_point, point)\n\u001b[1;32m    153\u001b[0m     squared_norm_add \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39msum(mobius_addition\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    154\u001b[0m     squared_norm_bp \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39msum(base_point\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/geomstats/geometry/poincare_ball.py:186\u001b[0m, in \u001b[0;36mPoincareBallMetric.mobius_add\u001b[0;34m(self, point_a, point_b, project_first)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Compute the Mobius addition of two points.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[39mThe Mobius addition is useful to compute the log and exp in the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39m    Result of the Mobius addition.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m project_first:\n\u001b[0;32m--> 186\u001b[0m     point_a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_space\u001b[39m.\u001b[39mprojection(point_a)\n\u001b[1;32m    187\u001b[0m     point_b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_space\u001b[39m.\u001b[39mprojection(point_b)\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/geomstats/geometry/poincare_ball.py:94\u001b[0m, in \u001b[0;36mPoincareBall.projection\u001b[0;34m(self, point)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNameError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong dimension, expected \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim)\n\u001b[1;32m     93\u001b[0m l2_norm \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(point, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m \u001b[39mif\u001b[39;00m gs\u001b[39m.\u001b[39many(l2_norm \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m gs\u001b[39m.\u001b[39matol):\n\u001b[1;32m     95\u001b[0m     projected_point \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39meinsum(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m...j,...->...j\u001b[39m\u001b[39m\"\u001b[39m, point \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m gs\u001b[39m.\u001b[39matol), \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m l2_norm\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mgs\u001b[39m.\u001b[39mmaximum(\u001b[39m-\u001b[39mprojected_point, \u001b[39m-\u001b[39mpoint)\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2412\u001b[0m, in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_any_dispatcher)\n\u001b[1;32m   2323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39many\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2324\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2325\u001b[0m \u001b[39m    Test whether any array element along a given axis evaluates to True.\u001b[39;00m\n\u001b[1;32m   2326\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2410\u001b[0m \n\u001b[1;32m   2411\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2412\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39mlogical_or, \u001b[39m'\u001b[39m\u001b[39many\u001b[39m\u001b[39m'\u001b[39m, axis, \u001b[39mNone\u001b[39;00m, out,\n\u001b[1;32m   2413\u001b[0m                           keepdims\u001b[39m=\u001b[39mkeepdims, where\u001b[39m=\u001b[39mwhere)\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/numpy/core/fromnumeric.py:72\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 72\u001b[0m     passkwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     73\u001b[0m                   \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue}\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m mu\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     76\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/numpy/core/fromnumeric.py:73\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     72\u001b[0m     passkwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m---> 73\u001b[0m                   \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue}\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m mu\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     76\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_neg = 10\n",
    "n_con = 10\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "folds = 5\n",
    "\n",
    "depths = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# dims = [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "dims = [4, 6, 8]\n",
    "\n",
    "y = np.array([x[1] for x in polblogs[\"labels\"]])\n",
    "cv = list(KFold(n_splits=folds, shuffle=True, random_state=42).split(y))\n",
    "\n",
    "results = []\n",
    "for embed_dim in dims:\n",
    "    try:\n",
    "        embed = HyperbolicEmbedding(dim=embed_dim, n_negative=n_neg, n_context=n_con, lr=lr, max_epochs=epochs)\n",
    "        polblogs_gs_embed = embed.embed(polblogs[\"geomstats_graph\"])\n",
    "        print(f\"Embedding shape: {polblogs_gs_embed.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Embed failed at {embed_dim}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Save embedding\n",
    "    np.savetxt(\n",
    "        f\"data/processed/geomstats_embeddings/polblogs/dim{embed_dim}_neg{n_neg}_con{n_con}_lr{lr}_ep{epochs}.tsv\",\n",
    "        polblogs_gs_embed,\n",
    "        delimiter=\"\\t\",\n",
    "    )\n",
    "\n",
    "    # Convert to hyperboloid\n",
    "    polblogs_hyperboloid = convert(polblogs_gs_embed, \"poincare\", \"hyperboloid\")\n",
    "\n",
    "    # Embedding scores\n",
    "    try:\n",
    "        n = polblogs_gs_embed.shape[0]\n",
    "        distortion, map_score = assess_embedding(polblogs_gs_embed)\n",
    "    except Exception as e:\n",
    "        print(f\"Distortion failed at {embed_dim}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for depth in depths:\n",
    "        try:\n",
    "            dt_scores = []\n",
    "            hdt_scores = []\n",
    "            for train, test in cv:\n",
    "                dt = DecisionTreeClassifier(max_depth=depth)\n",
    "                dt.fit(polblogs_hyperboloid[train], y[train])\n",
    "                dt_scores.append(dt.score(polblogs_hyperboloid[test], y[test]))\n",
    "\n",
    "                hdt = HyperbolicDecisionTreeClassifier(max_depth=depth)\n",
    "                hdt.fit(polblogs_hyperboloid[train], y[train])\n",
    "                hdt_scores.append(hdt.score(polblogs_hyperboloid[test], y[test]))\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Dim\": embed_dim,\n",
    "                    \"Depth\": depth,\n",
    "                    \"Score_DT\": np.mean(dt_scores),\n",
    "                    \"Std_DT\": np.std(dt_scores),\n",
    "                    \"Score_HDT\": np.mean(hdt_scores),\n",
    "                    \"Std_HDT\": np.std(hdt_scores),\n",
    "                    \"Distortion\": distortion,\n",
    "                    \"MAP\": map_score,\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"DT failed at {embed_dim}, {depth}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Overwrite for each embedding dimension\n",
    "    results = pd.DataFrame(results)\n",
    "    results.to_csv(\n",
    "        f\"data/processed/geomstats_embeddings/polblogs/results_neg{n_neg}_con{n_con}_lr{lr}_ep{epochs}.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperbolicDecisionTreeClassifier() \tfootball:\t0.3478 +/- 0.0778\n",
      "HyperbolicDecisionTreeClassifier() \tkarate:\t0.9314 +/- 0.0714\n",
      "HyperbolicDecisionTreeClassifier() \tpolblogs:\t0.9147 +/- 0.0163\n",
      "HyperbolicDecisionTreeClassifier() \tpolbooks:\t0.8210 +/- 0.0811\n",
      "\n",
      "HyperbolicRandomForestClassifier() \tfootball:\t0.3443 +/- 0.0684\n",
      "HyperbolicRandomForestClassifier() \tkarate:\t0.9371 +/- 0.0709\n",
      "HyperbolicRandomForestClassifier() \tpolblogs:\t0.9222 +/- 0.0134\n",
      "HyperbolicRandomForestClassifier() \tpolbooks:\t0.7981 +/- 0.0926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load from hSVM instead\n",
    "\n",
    "# Use micro-F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for clf in [\n",
    "    HyperbolicDecisionTreeClassifier(weights=\"balanced\"),\n",
    "    HyperbolicRandomForestClassifier(n_estimators=100, weights=\"balanced\"),\n",
    "]:\n",
    "    for dataset in [\"football\", \"karate\", \"polblogs\", \"polbooks\"]:\n",
    "        scores = []\n",
    "        for run in [1, 2, 3, 4, 5]:\n",
    "            data = loadmat(f\"hyplinear/data/realnet/{dataset}_data_{run}.mat\")\n",
    "            hyperboloid = convert(data[\"B\"], \"poincare\", \"hyperboloid\")\n",
    "            labels = data[\"label\"].ravel()\n",
    "            labels = np.unique(labels, return_inverse=True)[1]\n",
    "            scores.extend(cross_val_score(clf, hyperboloid, labels, cv=StratifiedKFold(5), scoring=\"f1_micro\"))\n",
    "        print(f\"{clf} \\t{dataset}:\\t{np.mean(scores):.4f} +/- {np.std(scores):.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
